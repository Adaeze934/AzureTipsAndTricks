(window.webpackJsonp=window.webpackJsonp||[]).push([[273],{710:function(e,s,a){"use strict";a.r(s);var n=a(69),t=Object(n.a)({},(function(){var e=this,s=e.$createElement,a=e._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[e._v("TIP")]),e._v(" "),a("p",[e._v("ðŸ”¥  ðŸ”¥  Download the FREE Azure Developer Guide eBook "),a("a",{attrs:{href:"http://aka.ms/azuredevebook?WT.mc_id=docs-azuredevtips-azureappsdev",target:"_blank",rel:"noopener noreferrer"}},[e._v("here"),a("OutboundLink")],1),e._v(".")]),e._v(" "),a("p",[e._v("ðŸ’¡ Learn more : "),a("a",{attrs:{href:"https://docs.microsoft.com/azure/cognitive-services/face/overview?WT.mc_id=docs-azuredevtips-azureappsdev",target:"_blank",rel:"noopener noreferrer"}},[e._v("What is the Azure Face service?"),a("OutboundLink")],1)]),e._v(" "),a("p",[e._v("ðŸ“º Watch the video : "),a("a",{attrs:{href:"https://youtu.be/EfdSD4EXX38?WT.mc_id=youtube-azuredevtips-azureappsdev",target:"_blank",rel:"noopener noreferrer"}},[e._v("How to identify faces with the Azure Face service"),a("OutboundLink")],1),e._v(".")])]),e._v(" "),a("h3",{attrs:{id:"how-to-identify-faces-with-the-azure-face-service"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#how-to-identify-faces-with-the-azure-face-service"}},[e._v("#")]),e._v(" How to identify faces with the Azure Face service")]),e._v(" "),a("h4",{attrs:{id:"automatic-face-detection"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#automatic-face-detection"}},[e._v("#")]),e._v(" Automatic face detection")]),e._v(" "),a("p",[e._v("Detecting and recognizing faces programmatically can be very difficult. Azure Face service provides this capability to you as-a-service. "),a("a",{attrs:{href:"https://docs.microsoft.com/azure/cognitive-services/face/overview?WT.mc_id=docs-azuredevtips-azureappsdev",target:"_blank",rel:"noopener noreferrer"}},[e._v("Azure Face service"),a("OutboundLink")],1),e._v(" is an API that you can call and use in your applications to detect faces and facial features in images. It comes with a pre-trained machine learning model, so you only have to use the service, not configure or manage it.")]),e._v(" "),a("p",[e._v("In this post, we'll use "),a("a",{attrs:{href:"https://docs.microsoft.com/azure/cognitive-services/face/overview?WT.mc_id=docs-azuredevtips-azureappsdev",target:"_blank",rel:"noopener noreferrer"}},[e._v("Azure Face service"),a("OutboundLink")],1),e._v(" to detect a face and facial features.")]),e._v(" "),a("h4",{attrs:{id:"prerequisites"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#prerequisites"}},[e._v("#")]),e._v(" Prerequisites")]),e._v(" "),a("p",[e._v("If you want to follow along, you'll need the following:")]),e._v(" "),a("ul",[a("li",[e._v("An Azure subscription (If you don't have an Azure subscription, create a "),a("a",{attrs:{href:"https://azure.microsoft.com/free/?WT.mc_id=azure-azuredevtips-azureappsdev",target:"_blank",rel:"noopener noreferrer"}},[e._v("free account"),a("OutboundLink")],1),e._v(" before you begin)")])]),e._v(" "),a("h4",{attrs:{id:"create-and-use-an-azure-cognitive-services-face-service"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#create-and-use-an-azure-cognitive-services-face-service"}},[e._v("#")]),e._v(" Create and use an Azure Cognitive Services Face Service")]),e._v(" "),a("p",[e._v("We'll start by creating a Face service resource in the Azure portal.")]),e._v(" "),a("ol",[a("li",[e._v("Go to the "),a("a",{attrs:{href:"https://portal.azure.com/?WT.mc_id=azure-azuredevtips-azureappsdev",target:"_blank",rel:"noopener noreferrer"}},[e._v("Azure portal"),a("OutboundLink")],1)]),e._v(" "),a("li",[e._v("Click the "),a("strong",[e._v("Create a resource")]),e._v(" button (the plus-sign in the top left corner)")]),e._v(" "),a("li",[e._v("Search for "),a("strong",[e._v("Face")]),e._v(', select the "Face" result and click '),a("strong",[e._v("Create")]),e._v(" "),a("ol",[a("li",[e._v("Select a "),a("strong",[e._v("Resource Group")])]),e._v(" "),a("li",[e._v("Pick a "),a("strong",[e._v("Region")]),e._v(" for the service")]),e._v(" "),a("li",[e._v("Fill in a "),a("strong",[e._v("Name")])]),e._v(" "),a("li",[e._v("Select a "),a("strong",[e._v("Pricing tier")]),e._v(". The "),a("strong",[e._v('"Free F0"')]),e._v(" tier is fine")]),e._v(" "),a("li",[e._v("Check the box to "),a("strong",[e._v("agree to the terms")])]),e._v(" "),a("li",[e._v("Click "),a("strong",[e._v("Review + create")]),e._v(" and then "),a("strong",[e._v("Create")])])])])]),e._v(" "),a("img",{attrs:{src:e.$withBase("/files/153create.png")}}),e._v(" "),a("p",[e._v("(Create a Face service resource)")]),e._v(" "),a("p",[e._v("When the Face service is created, navigate to it in the Azure portal.")]),e._v(" "),a("ol",[a("li",[e._v("In the Face service, click on the "),a("strong",[e._v("Quick start")]),e._v(" menu")]),e._v(" "),a("li",[e._v("We will use the API console to test the service. Click on "),a("strong",[e._v("API console")])]),e._v(" "),a("li",[e._v("Scroll down and select the "),a("strong",[e._v("Azure region")]),e._v(" in which you created the service. This will reload the page and makes sure that we are calling the correct service endpoint")]),e._v(" "),a("li",[e._v("We will enter all the information to make an API call to the Face service and test it. Scroll to the "),a("strong",[e._v("Query parameters")])])]),e._v(" "),a("img",{attrs:{src:e.$withBase("/files/153result1.png")}}),e._v(" "),a("p",[e._v("(Query parameters in the API Console)")]),e._v(" "),a("ol",[a("li",[e._v("For "),a("strong",[e._v("returnFaceAttributes")]),e._v(", enter "),a("strong",[e._v('"age,gender,headPose,smile,facialHair,glasses,emotion,hair,makeup,occlusion,accessories,blur,exposure,noise"')]),e._v(". You can find a list of all possible face attributes "),a("a",{attrs:{href:"https://docs.microsoft.com/azure/cognitive-services/face/concepts/face-detection#attributes?WT.mc_id=docs-azuredevtips-azureappsdev",target:"_blank",rel:"noopener noreferrer"}},[e._v("here"),a("OutboundLink")],1)]),e._v(" "),a("li",[e._v("Change the "),a("strong",[e._v("detectionModel")]),e._v(" to "),a("strong",[e._v("detection_01")])]),e._v(" "),a("li",[e._v("Go to "),a("strong",[e._v("Headers")]),e._v(". You need to enter the Face service subscription key here\n"),a("ol",[a("li",[e._v("Go back to the Face service in the Azure portal")]),e._v(" "),a("li",[e._v("Navigate to the "),a("strong",[e._v("Keys and Endpoint")]),e._v(" menu")]),e._v(" "),a("li",[e._v("Copy "),a("strong",[e._v("KEY 1")])])])])]),e._v(" "),a("img",{attrs:{src:e.$withBase("/files/153keys.png")}}),e._v(" "),a("p",[e._v("(Keys and endpoints of the Face service)")]),e._v(" "),a("ol",{attrs:{start:"4"}},[a("li",[e._v("Back in the API console, paste the "),a("strong",[e._v("key value")]),e._v(" in the "),a("strong",[e._v("Ocp-Apim-Subscription-Key")]),e._v(" field")]),e._v(" "),a("li",[e._v('In the request body, change the url value to "https://upload.wikimedia.org/wikipedia/commons/c/c3/RH_Louise_Lillian_Gish.jpg". This is a sample picture on wikipedia')])]),e._v(" "),a("img",{attrs:{src:e.$withBase("/files/153example.png")}}),e._v(" "),a("p",[e._v("(Sample picture on wikipedia)")]),e._v(" "),a("ol",{attrs:{start:"7"}},[a("li",[e._v("Click "),a("strong",[e._v("Send")]),e._v(" to send the request to the Face service")]),e._v(" "),a("li",[e._v("The "),a("strong",[e._v("Response status")]),e._v(" should be "),a("strong",[e._v("200 OK")]),e._v(" if everything went alright. This should result in a "),a("strong",[e._v("Response content")]),e._v(" that looks like the one below. This shows that one face was detected in the image, and that the face is likely to be of a female, 23 years old, without glasses and with brown hair. Pretty cool, right?")])]),e._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('x-envoy-upstream-service-time: 533\napim-request-id: c35cf15b-d1ac-4b36-9c13-aaf758daaff4\nStrict-Transport-Security: max-age=31536000; includeSubDomains; preload\nx-content-type-options: nosniff\nCSP-Billing-Usage: CognitiveServices.Face.Transaction=1\nDate: Fri, 07 15:13:42 GMT\nContent-Length: 1019\nContent-Type: application/json; charset=utf-8\n\n[{\n  "faceId": "be10f68d-b895-40b6-b3bb-e57bde7fcd9c",\n  "faceRectangle": {\n    "top": 131,\n    "left": 177,\n    "width": 162,\n    "height": 162\n  },\n  "faceAttributes": {\n    "smile": 0.001,\n    "headPose": {\n      "pitch": -5.7,\n      "roll": -9.1,\n      "yaw": -34.1\n    },\n    "gender": "female",\n    "age": 23.0,\n    "facialHair": {\n      "moustache": 0.0,\n      "beard": 0.0,\n      "sideburns": 0.0\n    },\n    "glasses": "NoGlasses",\n    "emotion": {\n      "anger": 0.0,\n      "contempt": 0.0,\n      "disgust": 0.0,\n      "fear": 0.0,\n      "happiness": 0.001,\n      "neutral": 0.987,\n      "sadness": 0.001,\n      "surprise": 0.01\n    },\n    "blur": {\n      "blurLevel": "low",\n      "value": 0.06\n    },\n    "exposure": {\n      "exposureLevel": "goodExposure",\n      "value": 0.67\n    },\n    "noise": {\n      "noiseLevel": "low",\n      "value": 0.0\n    },\n    "makeup": {\n      "eyeMakeup": true,\n      "lipMakeup": true\n    },\n    "accessories": [],\n    "occlusion": {\n      "foreheadOccluded": false,\n      "eyeOccluded": false,\n      "mouthOccluded": false\n    },\n    "hair": {\n      "bald": 0.01,\n      "invisible": false,\n      "hairColor": [{\n        "color": "brown",\n        "confidence": 1.0\n      }, {\n        "color": "gray",\n        "confidence": 0.53\n      }, {\n        "color": "black",\n        "confidence": 0.51\n      }, {\n        "color": "blond",\n        "confidence": 0.13\n      }, {\n        "color": "red",\n        "confidence": 0.13\n      }, {\n        "color": "other",\n        "confidence": 0.02\n      }, {\n        "color": "white",\n        "confidence": 0.0\n      }]\n    }\n  }\n}]\n')])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br"),a("span",{staticClass:"line-number"},[e._v("3")]),a("br"),a("span",{staticClass:"line-number"},[e._v("4")]),a("br"),a("span",{staticClass:"line-number"},[e._v("5")]),a("br"),a("span",{staticClass:"line-number"},[e._v("6")]),a("br"),a("span",{staticClass:"line-number"},[e._v("7")]),a("br"),a("span",{staticClass:"line-number"},[e._v("8")]),a("br"),a("span",{staticClass:"line-number"},[e._v("9")]),a("br"),a("span",{staticClass:"line-number"},[e._v("10")]),a("br"),a("span",{staticClass:"line-number"},[e._v("11")]),a("br"),a("span",{staticClass:"line-number"},[e._v("12")]),a("br"),a("span",{staticClass:"line-number"},[e._v("13")]),a("br"),a("span",{staticClass:"line-number"},[e._v("14")]),a("br"),a("span",{staticClass:"line-number"},[e._v("15")]),a("br"),a("span",{staticClass:"line-number"},[e._v("16")]),a("br"),a("span",{staticClass:"line-number"},[e._v("17")]),a("br"),a("span",{staticClass:"line-number"},[e._v("18")]),a("br"),a("span",{staticClass:"line-number"},[e._v("19")]),a("br"),a("span",{staticClass:"line-number"},[e._v("20")]),a("br"),a("span",{staticClass:"line-number"},[e._v("21")]),a("br"),a("span",{staticClass:"line-number"},[e._v("22")]),a("br"),a("span",{staticClass:"line-number"},[e._v("23")]),a("br"),a("span",{staticClass:"line-number"},[e._v("24")]),a("br"),a("span",{staticClass:"line-number"},[e._v("25")]),a("br"),a("span",{staticClass:"line-number"},[e._v("26")]),a("br"),a("span",{staticClass:"line-number"},[e._v("27")]),a("br"),a("span",{staticClass:"line-number"},[e._v("28")]),a("br"),a("span",{staticClass:"line-number"},[e._v("29")]),a("br"),a("span",{staticClass:"line-number"},[e._v("30")]),a("br"),a("span",{staticClass:"line-number"},[e._v("31")]),a("br"),a("span",{staticClass:"line-number"},[e._v("32")]),a("br"),a("span",{staticClass:"line-number"},[e._v("33")]),a("br"),a("span",{staticClass:"line-number"},[e._v("34")]),a("br"),a("span",{staticClass:"line-number"},[e._v("35")]),a("br"),a("span",{staticClass:"line-number"},[e._v("36")]),a("br"),a("span",{staticClass:"line-number"},[e._v("37")]),a("br"),a("span",{staticClass:"line-number"},[e._v("38")]),a("br"),a("span",{staticClass:"line-number"},[e._v("39")]),a("br"),a("span",{staticClass:"line-number"},[e._v("40")]),a("br"),a("span",{staticClass:"line-number"},[e._v("41")]),a("br"),a("span",{staticClass:"line-number"},[e._v("42")]),a("br"),a("span",{staticClass:"line-number"},[e._v("43")]),a("br"),a("span",{staticClass:"line-number"},[e._v("44")]),a("br"),a("span",{staticClass:"line-number"},[e._v("45")]),a("br"),a("span",{staticClass:"line-number"},[e._v("46")]),a("br"),a("span",{staticClass:"line-number"},[e._v("47")]),a("br"),a("span",{staticClass:"line-number"},[e._v("48")]),a("br"),a("span",{staticClass:"line-number"},[e._v("49")]),a("br"),a("span",{staticClass:"line-number"},[e._v("50")]),a("br"),a("span",{staticClass:"line-number"},[e._v("51")]),a("br"),a("span",{staticClass:"line-number"},[e._v("52")]),a("br"),a("span",{staticClass:"line-number"},[e._v("53")]),a("br"),a("span",{staticClass:"line-number"},[e._v("54")]),a("br"),a("span",{staticClass:"line-number"},[e._v("55")]),a("br"),a("span",{staticClass:"line-number"},[e._v("56")]),a("br"),a("span",{staticClass:"line-number"},[e._v("57")]),a("br"),a("span",{staticClass:"line-number"},[e._v("58")]),a("br"),a("span",{staticClass:"line-number"},[e._v("59")]),a("br"),a("span",{staticClass:"line-number"},[e._v("60")]),a("br"),a("span",{staticClass:"line-number"},[e._v("61")]),a("br"),a("span",{staticClass:"line-number"},[e._v("62")]),a("br"),a("span",{staticClass:"line-number"},[e._v("63")]),a("br"),a("span",{staticClass:"line-number"},[e._v("64")]),a("br"),a("span",{staticClass:"line-number"},[e._v("65")]),a("br"),a("span",{staticClass:"line-number"},[e._v("66")]),a("br"),a("span",{staticClass:"line-number"},[e._v("67")]),a("br"),a("span",{staticClass:"line-number"},[e._v("68")]),a("br"),a("span",{staticClass:"line-number"},[e._v("69")]),a("br"),a("span",{staticClass:"line-number"},[e._v("70")]),a("br"),a("span",{staticClass:"line-number"},[e._v("71")]),a("br"),a("span",{staticClass:"line-number"},[e._v("72")]),a("br"),a("span",{staticClass:"line-number"},[e._v("73")]),a("br"),a("span",{staticClass:"line-number"},[e._v("74")]),a("br"),a("span",{staticClass:"line-number"},[e._v("75")]),a("br"),a("span",{staticClass:"line-number"},[e._v("76")]),a("br"),a("span",{staticClass:"line-number"},[e._v("77")]),a("br"),a("span",{staticClass:"line-number"},[e._v("78")]),a("br"),a("span",{staticClass:"line-number"},[e._v("79")]),a("br"),a("span",{staticClass:"line-number"},[e._v("80")]),a("br"),a("span",{staticClass:"line-number"},[e._v("81")]),a("br"),a("span",{staticClass:"line-number"},[e._v("82")]),a("br"),a("span",{staticClass:"line-number"},[e._v("83")]),a("br"),a("span",{staticClass:"line-number"},[e._v("84")]),a("br"),a("span",{staticClass:"line-number"},[e._v("85")]),a("br"),a("span",{staticClass:"line-number"},[e._v("86")]),a("br"),a("span",{staticClass:"line-number"},[e._v("87")]),a("br"),a("span",{staticClass:"line-number"},[e._v("88")]),a("br"),a("span",{staticClass:"line-number"},[e._v("89")]),a("br"),a("span",{staticClass:"line-number"},[e._v("90")]),a("br"),a("span",{staticClass:"line-number"},[e._v("91")]),a("br"),a("span",{staticClass:"line-number"},[e._v("92")]),a("br")])]),a("h4",{attrs:{id:"conclusion"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#conclusion"}},[e._v("#")]),e._v(" Conclusion")]),e._v(" "),a("p",[e._v("You can use the "),a("a",{attrs:{href:"https://docs.microsoft.com/azure/cognitive-services/face/overview?WT.mc_id=docs-azuredevtips-azureappsdev",target:"_blank",rel:"noopener noreferrer"}},[e._v("Azure Face service"),a("OutboundLink")],1),e._v(" to detect faces and facial features, just by calling an API. Go and check it out!")])])}),[],!1,null,null,null);s.default=t.exports}}]);